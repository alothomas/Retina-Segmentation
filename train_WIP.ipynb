{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import cv2\n", "import numpy as np\n", "from tqdm import tqdm\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import DataLoader, Dataset\n", "import torchvision.transforms as transforms\n", "import matplotlib.pyplot as plt\n", "import albumentations as A\n", "from albumentations.pytorch import ToTensorV2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from resnet50_unet import UNetWithResnet50Encoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.cuda.empty_cache()\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DiceLoss(nn.Module):\n", "    def __init__(self, weight=None, size_average=True):\n", "        super(DiceLoss, self).__init__()\n", "    def forward(self, inputs, targets, smooth=1):\n", "        \n", "        #inputs = F.sigmoid(inputs)       \n", "        \n", "        #flatten label and prediction tensors\n", "        inputs = inputs.view(-1)\n", "        targets = targets.view(-1)\n", "        \n", "        intersection = (inputs * targets).sum()                            \n", "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n", "        \n", "        return 1 - dice"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import cv2\n", "import numpy as np\n", "from torch.utils.data import Dataset\n", "import torch\n", "import albumentations as A\n", "from albumentations.pytorch import ToTensorV2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CustomDataset(Dataset):\n", "    def __init__(self, image_dir, mask_dir, augment=True):\n", "        self.image_dir = image_dir\n", "        self.mask_dir = mask_dir\n", "        # List image files, assuming they're named 'image_*.png'\n", "        self.image_files = [f for f in os.listdir(image_dir) if f.startswith('image_')]\n", "        self.augment = augment\n", "        self.transform = A.Compose([\n", "            A.OneOf([\n", "                A.Rotate(limit=(180, 180), p=0.5),\n", "                A.Rotate(limit=(90, 90), p=0.5),\n", "            ], p=1.0),\n", "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n", "            A.ToFloat(max_value=255.0),\n", "            ToTensorV2(),\n", "        ])\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def __len__(self):\n", "        return len(self.image_files)\n", "    def __getitem__(self, idx):\n", "        # Use the image filename to construct the corresponding mask filename\n", "        image_filename = self.image_files[idx]\n", "        # Extract ID from the image filename\n", "        image_id = image_filename.split('_')[1].split('.')[0]\n", "        mask_filename = f\"mask_{image_id}.png\"\n", "        image_path = os.path.join(self.image_dir, image_filename)\n", "        mask_path = os.path.join(self.mask_dir, mask_filename)\n", "        \n", "        # Load and preprocess the image and mask\n", "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n", "        image = cv2.resize(image, (512, 512))\n", "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n", "        mask = cv2.resize(mask, (512, 512))\n", "        _, mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        image = np.stack([image] * 3, axis=-1)\n", "        if self.augment:\n", "            augmented = self.transform(image=image, mask=mask)\n", "        else:\n", "            # Apply ToTensorV2 and conversion to float for non-augmented path\n", "            augmented = A.Compose([\n", "            A.ToFloat(max_value=255.0),\n", "            ToTensorV2(),\n", "            ])(image=image, mask=mask)\n", "        image = augmented['image']\n", "        mask = augmented['mask']\n", "        return image, mask.float()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Data Loaders"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BATCH_SIZE = 8\n", "train_dataset = CustomDataset('data_model/train/images' , 'data_model/train/masks', augment=True)\n", "val_dataset = CustomDataset('data_model/test/images', 'data_model/test/masks')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n", "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Model, Optimizer, and Loss Functions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = UNetWithResnet50Encoder(n_classes=1).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["odel.load_state_dict(torch.load('output_dir2/model_epoch_1.pth'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["cheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n", "loss_fn = DiceLoss().to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_images_and_masks(dataset, num_imgs=3):\n", "    fig, axs = plt.subplots(num_imgs, 2, figsize=(10, num_imgs * 5))\n", "    \n", "    for i in range(num_imgs):\n", "        idx = np.random.randint(0, len(dataset))  # Randomly select an index\n", "        image, mask = dataset[idx]\n", "        \n", "        # The image tensor might be normalized. Since we're skipping denormalization,\n", "        # the image could appear with altered contrast/brightness.\n", "        image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC for plotting\n", "        \n", "        mask = mask.squeeze().numpy()  # Remove channel dim for mask (C=1)\n", "        \n", "        # Plot image\n", "        axs[i, 0].imshow(image, cmap='gray')\n", "        axs[i, 0].set_title(f\"Image {idx}\")\n", "        axs[i, 0].axis('off')\n", "        \n", "        # Plot mask\n", "        axs[i, 1].imshow(mask, cmap='gray')\n", "        axs[i, 1].set_title(f\"Mask {idx}\")\n", "        axs[i, 1].axis('off')\n", "    \n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display images and masks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_images_and_masks(train_dataset, num_imgs=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Training Function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_one_epoch(epoch):\n", "    model.train()\n", "    loss_total = 0.0\n", "    loss_throughout_epoch = []\n", "    for input_img, mask in tqdm(train_loader, desc=f'Training epoch {epoch}'):\n", "        input_img, mask = input_img.to(device), mask.to(device)\n", "        optimizer.zero_grad()\n", "        output = model(input_img)\n", "        loss = loss_fn(output, mask)\n\n", "        # Combine losses and backpropagate, normalize them against each other\n", "        loss.backward()\n", "        optimizer.step()\n\n", "        # Accumulate individual losses for logging\n", "        loss_total += loss.item()\n", "        loss_throughout_epoch.append(loss.item())\n", "    \n", "    # Save graph of loss throughout epoch\n", "    plt.figure(figsize=(12, 8))\n", "    plt.plot(loss_throughout_epoch, label='Loss')\n", "    plt.title('Loss')\n", "    plt.legend()\n", "    plt.tight_layout()\n", "    # Create the directory if it doesn't exist\n", "    if not os.path.exists('st_output_dir'):\n", "        os.makedirs('st_output_dir')\n", "    plt.savefig(f'st_output_dir/internalloss_graph_epoch_{epoch}.png')\n", "    plt.close()\n", "    return loss_total / len(train_loader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Validation Function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def validate(epoch):\n", "    model.eval()\n", "    loss_total = 0.0\n", "    with torch.no_grad():\n", "        for input_img, mask in tqdm(val_loader, desc=f'Validating epoch {epoch}'):\n", "            input_img, mask = input_img.to(device), mask.to(device)\n", "            output = model(input_img)\n", "            loss = loss_fn(output, mask)\n", "            loss_total += loss.item()\n", "    return loss_total / len(val_loader)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot Loss Function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_loss(epoch,train_inp_losses, val_inp_losses):\n", "    plt.figure(figsize=(12, 8))\n\n", "    # Ensure the x-axis matches the number of epochs\n", "    epochs = range(1, epoch + 2)  # +1 for zero-based indexing, +1 for inclusive range\n", "    plt.plot(epochs, train_inp_losses, label='Train Loss')\n", "    plt.plot(epochs, val_inp_losses, label='Val Loss')\n", "    plt.title('Loss')\n", "    plt.legend()\n", "    plt.tight_layout()\n", "    plt.savefig(f'st_output_dir/loss_graph.png')\n", "    plt.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save Model Function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_model(model, path):\n", "    torch.save(model.state_dict(), path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_inp_losses = []\n", "val_inp_losses = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Main Training Loop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_epochs = 10\n", "for epoch in range(num_epochs):\n", "    train_inp_loss = train_one_epoch(epoch)\n", "    scheduler.step(train_inp_loss)\n", "    val_inp_loss = validate(epoch)\n", "    train_inp_losses.append(train_inp_loss)\n", "    val_inp_losses.append(val_inp_loss)\n", "    print(f'Epoch {epoch}, Train Loss: {train_inp_loss}')\n", "    print(f'Epoch {epoch}, Val  Loss: {val_inp_loss}')\n", "    save_model(model,f'st_output_dir/model_epoch_{epoch}.pth')\n", "    plot_loss(epoch, train_inp_losses, val_inp_losses)\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize(image, true_mask=None, predicted_mask=None):\n", "    \"\"\"Visualize comparison between input image, true mask, and predicted mask.\"\"\"\n", "    fig, axs = plt.subplots(1, 3, figsize=(20, 10))  # Adjust the size as needed\n", "    axs[0].imshow(image, cmap='gray')\n", "    axs[0].set_title('Input Image')\n", "    axs[0].axis('off')\n", "    if true_mask is not None:\n", "        axs[1].imshow(true_mask, cmap='gray')\n", "        axs[1].set_title('True Mask')\n", "        axs[1].axis('off')\n", "    else:\n", "        axs[1].axis('off')  # Hide the axis if true mask is not provided\n", "    axs[2].imshow(predicted_mask, cmap='gray')\n", "    axs[2].set_title('Predicted Mask')\n", "    axs[2].axis('off')\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_and_visualize(model, dataset, device):\n", "    model.eval()  \n", "    with torch.no_grad(): \n", "        for i in range(len(dataset)):\n", "            input_img, true_mask = dataset[i]  \n", "            input_img_unsqueeze = input_img.unsqueeze(0).to(device)  \n", "            \n", "            # Predict\n", "            pred_mask = model(input_img_unsqueeze)\n", "            pred_mask = pred_mask.squeeze().cpu().numpy().astype(np.uint8)\n", "            pred_mask = pred_mask > 0.5  \n\n", "            # Convert the input image and true mask to numpy for visualization, if available\n", "            input_img_np = input_img.squeeze().permute(1, 2, 0).cpu().numpy()  # Assuming input_img is CxHxW\n", "            input_img_np = (input_img_np * 0.5) + 0.5  # Assuming normalization was done with mean=0.5, std=0.5\n", "            true_mask_np = true_mask.squeeze().cpu().numpy() if true_mask is not None else None\n\n", "            # Use the visualize function\n", "            visualize(\n", "                image=input_img_np,\n", "                true_mask=true_mask_np,\n", "                predicted_mask=pred_mask\n", "            )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["real_data_dataset = CustomDataset('data_model/train/images', 'data_model/train/masks', augment=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the model (ensure the model is already trained and weights are loaded)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = UNetWithResnet50Encoder(n_classes=1).to(device)\n", "model.load_state_dict(torch.load('st_output_dir\\model_epoch_9.pth'))\n", "# Predict and visualize on the real data\n", "predict_and_visualize(model, real_data_dataset, device)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}